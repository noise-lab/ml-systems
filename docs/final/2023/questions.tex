\section*{Machine Learning Pipeline}
\vspace*{-0.15in}

\prob{3} One of the challenges with training a machine learning model is overfitting---whereby a model
performs well on the training data but poorly on the test data. Assume a ``standard'' traffic
classification problem, like service identification or QoE determination. Give an example of a feature from network traffic which, if
included in a model, could result in overfitting to the training data.

\vspace{0.1in}
\answerbox{1.5}{}
\eprob

\section*{Supervised Learning}
\vspace*{-0.15in}

\prob{2} Random forest models can perform classification using a combination of feature types as input (e.g.,
categorical, numerical).

\vspace{0.1in}
\begin{center}
    \yesnoyes
\end{center}
\eprob

\prob{2} Deep learning models that operate on raw traffic input (like nPrint) always outperform simpler models like k-nearest neighbors and linear regression models that take semantic features as input.

\vspace{0.1in}
\begin{center}
    \yesnono
\end{center}
\eprob

\prob{3} Why or why not?

\vspace{0.1in}
\answerbox{1.5}{}
\eprob

\section*{Unsupervised Learning}
\vspace*{-0.15in}

\prob{2} Which of the following are possible applications of unsupervised learning? (Select all that apply.)

\vspace{0.05in}
\begin{center}
    \begin{tabularx}{0.9\textwidth}{X}
        \correctanswercircle{Detecting unusual traffic volumes or destinations} \\
        \correctanswercircle{Identifying changes that could indicate a network failure} \\
        \answercircle{Identifying the application that generated a traffic trace.} \\
        \correctanswercircle{Clustering traffic traces into groups with similar behavior (e.g., to identify a botnet).}
    \end{tabularx}
\end{center}
\eprob

\prob{2} Can you ever evaluate an unsupervised learning model using precision and recall?

\vspace{0.1in}
\begin{center}
    \yesnoyes
\end{center}
\eprob

\prob{3} If so, explain how. If not, why not?

\vspace{0.1in}
\answerbox{1.5}{}
\eprob

\prob{3} Describe (with illustration, if you like) an example dataset where density-based clustering may
produce more ``meaningful'' clusters than k-means clustering.

\vspace{0.1in}
\answerbox{1.8}{}
\eprob

\section*{Looking Ahead}
\vspace*{-0.15in}

\prob{1} Transformers and large language models have shown promise in learning long-term temporal
and semantic relationships across multiple traffic flows (e.g., a TCP connection that follows a DNS lookup, etc.). Can you think of a
classification problem where an nPrint and simple classifier would fail but such a classifier model might
perform better? (I know...I said I wouldn't ask, but it's only one point!)

\vspace{0.1in}
\answerbox{1.5}{}
\eprob

\section*{Feedback}
\vspace*{-0.15in}

\prob{2} 1. Your favorite topic or activity in this course. 2. One topic you'd like to see covered that was not
covered.

\vspace{0.1in}
\answerbox{1.2}{}
\eprob
