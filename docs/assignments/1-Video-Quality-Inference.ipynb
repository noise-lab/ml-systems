{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zbGBJegvBuXV"
   },
   "source": [
    "# Assignment: Video Quality Inference\n",
    "\n",
    "To this point in the class, you have learned various techniques for leading and analyzing packet captures of various types, generating features from those packet captures, and training and evaluating models using those features.\n",
    "\n",
    "In this assignment, you will put all of this together, using a network traffic trace to train a model to automatically infer video quality of experience from a labeled traffic trace.\n",
    "\n",
    "## Part 1: Warmup\n",
    "\n",
    "The first part of this assignment builds directly on the hands-on activities but extends them slightly.\n",
    "\n",
    "### Extract Features from the Network Traffic\n",
    "\n",
    "Load the `netflix.pcap` file, which is a packet trace that includes network traffic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOPPsKpYB6PS"
   },
   "source": [
    "### Identifying the Service Type\n",
    "\n",
    "Use the DNS traffic to filter the packet trace for Netflix traffic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qFV6q2OCCsK"
   },
   "source": [
    "### Generate Statistics\n",
    "\n",
    "Generate statistics and features for the Netflix traffic flows. Use the `netml` library or any other technique that you choose to generate a set of features that you think would be good features for your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0qFV6q2OCCsK"
   },
   "source": [
    "**Write a brief justification for the features that you have chosen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBCP_2SBC2xj"
   },
   "source": [
    "### Inferring Segment downloads\n",
    "\n",
    "In addition to the features that you could generate using the `netml` library or similar, add to your feature vector a \"segment downloads rate\" feature, which indicates the number of video segments downloaded for a given time window.\n",
    "\n",
    "Note: If you are using the `netml` library, generating features with `SAMP` style options may be useful, as this option gives you time windows, and you can then simply add the segment download rate to that existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Video Quality Inference\n",
    "\n",
    "You will now load the complete video dataset from a previous study to train and test models based on these features to automatically infer the quality of a streaming video flow.\n",
    "\n",
    "For this part of the assignment, you will need two pickle files, which we provide for you by running the code below:\n",
    "\n",
    "```\n",
    "\n",
    "!gdown 'https://drive.google.com/uc?id=1N-Cf4dJ3fpak_AWgO05Fopq_XPYLVqdS' -O netflix_session.pkl\n",
    "!gdown 'https://drive.google.com/uc?id=1PHvEID7My6VZXZveCpQYy3lMo9RvMNTI' -O video_dataset.pkl\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the File\n",
    "\n",
    "Load the video dataset pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the File\n",
    "\n",
    "1. The dataset contains video resolutions that are not valid. Remove entries in the dataset that do not contain a valid video resolution. Valid resolutions are 280, 360, 480, 720, 1080."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The file also contains columns that are unnecessary (in fact, unhelpful!) for performing predictions. Identify those columns, and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly explain why you removed those columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Your Data\n",
    "\n",
    "Prepare your data matrix, determine your features and labels, and perform a train-test split on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Tune Your Model\n",
    "\n",
    "1. Select a model of your choice.\n",
    "2. Train the model using your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Your Model\n",
    "\n",
    "Perform hyperparameter tuning to find optimal parameters for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Your Model\n",
    "\n",
    "Evaluate your model accuracy according to the following metrics:\n",
    "\n",
    "1. Accuracy\n",
    "2. F1 Score\n",
    "3. Confusion Matrix\n",
    "4. ROC/AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Predict the Ongoing Resolution of a Real Netflix Session\n",
    "\n",
    "Now that you have your model, it's time to put it in practice!\n",
    "\n",
    "Use a preprocessed Netflix video session to infer **and plot** the resolution at 10-second time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM0Cd1i3qtplCsVAB9qTjxA",
   "collapsed_sections": [],
   "name": "pcap_processing_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
